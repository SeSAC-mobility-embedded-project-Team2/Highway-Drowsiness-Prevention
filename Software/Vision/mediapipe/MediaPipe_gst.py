import cv2
import mediapipe as mp
import numpy as np
import subprocess
import os

# --- ì„¤ì • ---
EAR_THRESHOLD = 0.21
SLEEP_FRAMES = 20
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]

def calculate_ear(landmarks, indices, w, h):
    coords = []
    for idx in indices:
        lm = landmarks[idx]
        coords.append(np.array([lm.x * w, lm.y * h]))
    v1 = np.linalg.norm(coords[1] - coords[5])
    v2 = np.linalg.norm(coords[2] - coords[4])
    h_dist = np.linalg.norm(coords[0] - coords[3])
    return (v1 + v2) / (2.0 * h_dist)

def main():
    # 1. ì¹´ë©”ë¼ ëª…ë ¹ì–´ ì„¤ì • (raw ë°ì´í„°ë¥¼ stdoutìœ¼ë¡œ ì¶œë ¥)
    # libcamera-vid ëŒ€ì‹  ë” ê°€ë²¼ìš´ rpicam-vid ì‚¬ìš©
    cmd = [
        'rpicam-vid',
        '-t', '0',
        '--width', '640',
        '--height', '480',
        '--inline',
        '--nopreview',
        '--codec', 'mjpeg',
        '-o', '-'  # ì¶œë ¥ ìœ„ì¹˜ë¥¼ stdout(í‘œì¤€ ì¶œë ¥)ìœ¼ë¡œ ì„¤ì •
    ]
    
    # í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)

    # 2. MediaPipe ì„¤ì •
    mp_face_mesh = mp.solutions.face_mesh
    face_mesh = mp_face_mesh.FaceMesh(
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )

    sleep_counter = 0
    bytes_data = b''

    print("ğŸš€ ë¼ì¦ˆë² ë¦¬íŒŒì´ 5 ì¹´ë©”ë¼ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")

    try:
        while True:
            # MJPEG ìŠ¤íŠ¸ë¦¼ì—ì„œ í•œ í”„ë ˆì„ì”© ì½ê¸° (FFD8 ~ FFD9 ì°¾ê¸°)
            bytes_data += process.stdout.read(1024)
            a = bytes_data.find(b'\xff\xd8')
            b = bytes_data.find(b'\xff\xd9')

            if a != -1 and b != -1:
                jpg = bytes_data[a:b+2]
                bytes_data = bytes_data[b+2:]
                
                # ì´ë¯¸ì§€ ë””ì½”ë”©
                image = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)
                if image is None: continue

                h, w, _ = image.shape
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                results = face_mesh.process(image_rgb)

                if results.multi_face_landmarks:
                    for face_landmarks in results.multi_face_landmarks:
                        left_ear = calculate_ear(face_landmarks.landmark, LEFT_EYE, w, h)
                        right_ear = calculate_ear(face_landmarks.landmark, RIGHT_EYE, w, h)
                        avg_ear = (left_ear + right_ear) / 2.0

                        if avg_ear < EAR_THRESHOLD:
                            sleep_counter += 1
                        else:
                            sleep_counter = 0

                        if sleep_counter > SLEEP_FRAMES:
                            cv2.putText(image, "SLEEPING ALERT!", (50, 100),
                                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

                        cv2.putText(image, f'EAR: {avg_ear:.2f}', (30, 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                cv2.imshow('Pi 5 Sleep Monitor (Pipe)', image)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

    except Exception as e:
        print(f"Error: {e}")
    finally:
        process.terminate()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()